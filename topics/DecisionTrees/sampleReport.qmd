---
title: "Decision Tree Challenge"
subtitle: "Feature Importance and Categorical Variable Encoding"
format:
  html: default
  pdf: default
execute:
  echo: true
  eval: true
---

# ðŸŒ³ Decision Tree Challenge - Feature Importance and Variable Encoding

## Challenge Overview

---
title: "Decision Tree Challenge"
subtitle: "Feature Importance and Categorical Variable Encoding"
format:
  html: default
  pdf: default
execute:
  echo: true
  eval: true
---

# ðŸŒ³ Decision Tree Challenge - Feature Importance and Variable Encoding

## Challenge Overview

**Your Mission:** Create a comprehensive Quarto document that demonstrates how decision trees measure feature importance, analyzes the critical differences between categorical and numerical variable encoding, and presents compelling evidence of why proper data preprocessing matters for interpretable machine learning. Then render the document to HTML and deploy it via GitHub Pages using the starter repository workflow.

## The Decision Tree Problem ðŸŽ¯

**The Core Problem:** Decision trees are often praised for their interpretability and ability to handle both numerical and categorical variables. But what happens when we encode categorical variables as numbers? How does this affect our understanding of feature importance?

**What is Feature Importance?** In decision trees, feature importance measures how much each variable contributes to reducing impurity (or improving prediction accuracy) across all splits in the tree. It's a key metric for understanding which variables matter most for your predictions.

::: {.callout-important}
## ðŸŽ¯ The Key Insight: Encoding Matters for Interpretability

**The problem:** When we encode categorical variables as numerical values (like 1, 2, 3, 4...), decision trees treat them as if they have a meaningful numerical order. This can completely distort our understanding of feature importance.

**Why this matters:** If a categorical variable like "Zip Code" (50010, 50011, 50012, 50013) is treated as a numerical variable, the tree might split on "Zip Code > 50012.5" instead of recognizing that this is really a categorical choice between discrete geographic areas where the order of numerical values has no meaningful interpretation.

**The connection:** Proper encoding preserves the true nature of categorical variables and gives us accurate feature importance rankings.
:::

**The Devastating Reality:** Even sophisticated machine learning models can give us completely wrong insights about feature importance if we don't properly encode our variables. A categorical variable that should be among the most important might appear irrelevant, while a numerical variable might appear artificially important.

## Mistaken Feature Importance: The Example of Zip Code

Here we load a dataset that has a categorical variable "Zip Code" and a numerical variable "Sale Price" along with a bunch of other truly numerical variables.  In this section, we will explore how the decision tree treats the "Zip Code" when it is mistakenly considered a numerical variable.

$$
\begin{aligned}
\text{Price} &\equiv \text{House Sale Price (our target variable)}\\
\text{Neighborhood} &\equiv \text{Categorical: Ames neighborhood}\\
\text{House Style} &\equiv \text{Categorical: Style of dwelling}\\
\text{Year Built} &\equiv \text{Numerical: Year house was constructed}\\
\text{Square Feet} &\equiv \text{Numerical: Total square footage}
\end{aligned}
$$

Let's assume we want to predict house prices using a decision tree with maximum depth of 3.

### Data Loading and Initial Exploration

::: {.panel-tabset}

### R

```{r}
#| label: load-data-r
#| echo: true
#| message: false
#| warning: false

# Load required libraries
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(rpart))
suppressPackageStartupMessages(library(rpart.plot))

# Load the Sales Price dataset
# Note: This loads the data from the buad442Fall2025 repository
sales_data <- read.csv("https://raw.githubusercontent.com/flyaflya/buad442Fall2025/refs/heads/main/datasets/salesPriceData.csv")

# Display basic information about the dataset
cat("Dataset dimensions:", dim(sales_data), "\n")
cat("Number of variables:", ncol(sales_data), "\n")
cat("Number of observations:", nrow(sales_data), "\n\n")

# Show first few rows
head(sales_data, 10)
```

```{r}
#| label: data-structure-r
#| echo: true
#| message: false
#| warning: false

# Examine data types and structure
str(sales_data)

# Summary statistics for key variables
summary(sales_data)
```

### Python

```{python}
#| label: load-data-python
#| echo: true

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Load the Sales Price dataset
# Note: This loads the data from the buad442Fall2025 repository
sales_data = pd.read_csv("https://raw.githubusercontent.com/flyaflya/buad442Fall2025/refs/heads/main/datasets/salesPriceData.csv")

print("Dataset loaded successfully!")

# Display basic information about the dataset
print(f"Dataset dimensions: {sales_data.shape}")
print(f"Number of variables: {sales_data.shape[1]}")
print(f"Number of observations: {sales_data.shape[0]}\n")

# Show first few rows
print("First 10 rows:")
sales_data.head(10)
```

```{python}
#| label: data-structure-python
#| echo: true

# Examine data types and structure
print("Data types:")
print(sales_data.dtypes)
print("\nData structure:")
print(sales_data.info())

# Summary statistics for key variables
print("\nSummary statistics for key variables:")
sales_data.describe(include='all')
```
:::

### Dataset Description

The Sales Price dataset contains real estate data with multiple variables describing various aspects of each property. Key variables include:

**Target Variable:**
- `SalePrice`: The sale price of the house (our prediction target)

**Key Variables:**
- `LotArea`: Lot size in square feet
- `YearBuilt`: Year the house was originally built
- `GrLivArea`: Above ground living area square feet
- `FullBath`: Number of full bathrooms
- `HalfBath`: Number of half bathrooms
- `BedroomAbvGr`: Number of bedrooms above grade
- `TotRmsAbvGrd`: Total rooms above grade
- `GarageCars`: Size of garage in car capacity
- `avgAreaIncome`: Average area income
- `zipCode`: Zip code of the property

