<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="BUAD 442">
<meta name="dcterms.date" content="2025-09-30">

<title>Interpretable Data Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="interpretableDataModels_presentation_files/libs/clipboard/clipboard.min.js"></script>
<script src="interpretableDataModels_presentation_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="interpretableDataModels_presentation_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="interpretableDataModels_presentation_files/libs/quarto-html/popper.min.js"></script>
<script src="interpretableDataModels_presentation_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="interpretableDataModels_presentation_files/libs/quarto-html/anchor.min.js"></script>
<link href="interpretableDataModels_presentation_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="interpretableDataModels_presentation_files/libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="interpretableDataModels_presentation_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="interpretableDataModels_presentation_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="interpretableDataModels_presentation_files/libs/bootstrap/bootstrap-bb462d781dde1847d9e3ccf7736099dd.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="interpretableDataModels_presentation.pptx"><i class="bi bi-file-slides"></i>Powerpoint</a></li></ul></div></div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Interpretable Data Models</h1>
<p class="subtitle lead">Understanding the Why Behind Data-Driven Predictions</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>BUAD 442 </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 30, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="interpretable-data-models" class="level1">
<h1>Interpretable Data Models</h1>
<section id="understanding-the-why-behind-data-driven-predictions" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-why-behind-data-driven-predictions">Understanding the Why Behind Data-Driven Predictions</h2>
<hr>
</section>
</section>
<section id="the-core-idea" class="level1">
<h1>The Core Idea</h1>
<section id="data-models-as-functions" class="level2">
<h2 class="anchored" data-anchor-id="data-models-as-functions">Data Models as Functions</h2>
<p>A data model is a function that represents how variables relate.</p>
<div class="notes">
<p>Data models can take different functional forms - either direct mappings or probability distributions.</p>
</div>
<hr>
</section>
</section>
<section id="direct-mappings" class="level1">
<h1>Direct Mappings</h1>
<p><span class="math inline">\(f: X \rightarrow Y\)</span></p>
<p>Turning inputs into outputs.</p>
<p><strong>Example:</strong> Linear regression predicting house prices from square footage.</p>
<div class="notes">
<p>Direct mappings are explicit functions that take inputs and produce outputs.</p>
</div>
<hr>
</section>
<section id="probability-distributions" class="level1">
<h1>Probability Distributions</h1>
<p><span class="math inline">\(p(X,Y)\)</span></p>
<p>Describing how variables co-vary and with what uncertainty.</p>
<p><strong>Example:</strong> Bayesian networks modeling disease symptoms and causes.</p>
<div class="notes">
<p>Probability distributions describe relationships with uncertainty rather than deterministic mappings.</p>
</div>
<hr>
</section>
<section id="what-is-interpretability" class="level1">
<h1>What is Interpretability?</h1>
<section id="one-liner-definition" class="level2">
<h2 class="anchored" data-anchor-id="one-liner-definition">One-Liner Definition</h2>
<p>An <strong>interpretable data model</strong> is a function whose structure is simple enough that humans can understand the relationships it encodes.</p>
<div class="notes">
<p>The key is that the structure must be simple enough for human understanding.</p>
</div>
<hr>
</section>
</section>
<section id="expanded-definition" class="level1">
<h1>Expanded Definition</h1>
<p>All models are functions, but their form varies.</p>
<p>Sometimes explicit mappings, other times joint distributions.</p>
<p>An interpretable model is transparent enough that people can trace the “why” behind its outputs.</p>
<div class="notes">
<p>The transparency allows users to understand the reasoning process.</p>
</div>
<hr>
</section>
<section id="key-characteristics" class="level1">
<h1>Key Characteristics</h1>
<ul>
<li><strong>Clear structure</strong>: easily understood relationships</li>
<li><strong>Human-scale parameters</strong>: coefficients, thresholds that make intuitive sense<br>
</li>
<li><strong>Traceable reasoning</strong>: ability to explain how predictions were reached</li>
</ul>
<div class="notes">
<p>These three characteristics make a model interpretable to humans.</p>
</div>
<hr>
</section>
<section id="interpretability-vs-explainability" class="level1">
<h1>Interpretability vs Explainability</h1>
<section id="interpretability" class="level2">
<h2 class="anchored" data-anchor-id="interpretability">Interpretability</h2>
<p><strong>Definition:</strong> The degree to which a model’s internal structure, parameters, and decision-making process can be understood by humans without requiring additional explanation tools.</p>
<p><strong>Focus:</strong> Built-in transparency of the model itself.</p>
<div class="notes">
<p>Interpretability is about the model’s inherent transparency.</p>
</div>
<hr>
</section>
</section>
<section id="interpretability-vs-explainability-1" class="level1">
<h1>Interpretability vs Explainability</h1>
<section id="explainability" class="level2">
<h2 class="anchored" data-anchor-id="explainability">Explainability</h2>
<p><strong>Definition:</strong> The ability to provide clear, causal reasoning for why a model made a specific prediction.</p>
<p><strong>Focus:</strong> Post-hoc analysis and explanation of model decisions.</p>
<div class="notes">
<p>Explainability comes after the fact and requires causal understanding.</p>
</div>
<hr>
</section>
</section>
<section id="the-causal-reasoning-challenge" class="level1">
<h1>The Causal Reasoning Challenge</h1>
<section id="correlation-vs.-causation-in-explanations" class="level2">
<h2 class="anchored" data-anchor-id="correlation-vs.-causation-in-explanations">Correlation vs.&nbsp;Causation in Explanations</h2>
<p>Most “explanations” from data models are actually just descriptions of correlations.</p>
<p>True explainability requires causal reasoning.</p>
<div class="notes">
<p>This is a critical distinction - correlation is not causation.</p>
</div>
<hr>
</section>
</section>
<section id="example-correlation-vs-causation" class="level1">
<h1>Example: Correlation vs Causation</h1>
<p><strong>Correlational explanation:</strong> “Maternal Tylenol use during pregnancy is associated with autism diagnosis in children”</p>
<p><strong>Causal explanation:</strong> “Maternal symptoms X, Y, and Z during pregnancy lead to both increased Tylenol use and increased autism risk in the child.”</p>
<div class="notes">
<p>The difference matters for actionability and trust.</p>
</div>
<hr>
</section>
<section id="why-interpretability-matters" class="level1">
<h1>Why Interpretability Matters</h1>
<section id="the-core-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-core-benefits">The Core Benefits</h2>
<ul>
<li><strong>Trust</strong>: Users and stakeholders can validate and believe results</li>
<li><strong>Actionability</strong>: Insights can be acted on because the logic is clear<br>
</li>
<li><strong>Debuggability</strong>: Problems can be identified and corrected</li>
<li><strong>Ethics</strong>: Transparency helps detect bias and unintended consequences</li>
</ul>
<div class="notes">
<p>These four benefits make interpretability crucial for real-world applications.</p>
</div>
<hr>
</section>
</section>
<section id="the-problem-with-black-boxes" class="level1">
<h1>The Problem with Black Boxes</h1>
<blockquote class="blockquote">
<p>“The problem is that a single metric, such as classification accuracy, is an incomplete description of most real-world tasks.” - Doshi-Velez and Kim (2017)</p>
</blockquote>
<div class="notes">
<p>Accuracy alone doesn’t tell the whole story about model performance.</p>
</div>
<hr>
</section>
<section id="the-trade-off" class="level1">
<h1>The Trade-off</h1>
<p>Do you just want to know <strong>what</strong> is predicted?</p>
<p>Or do you want to know <strong>why</strong> the prediction was made and possibly pay for the interpretability with a drop in predictive performance?</p>
<div class="notes">
<p>This is the fundamental trade-off in model selection.</p>
</div>
<hr>
</section>
<section id="key-reasons-for-interpretability" class="level1">
<h1>Key Reasons for Interpretability</h1>
<section id="human-curiosity-learning" class="level2">
<h2 class="anchored" data-anchor-id="human-curiosity-learning">Human Curiosity &amp; Learning</h2>
<p>Humans have a mental model of their environment that is updated when something unexpected happens.</p>
<p>This update is performed by finding an explanation for the unexpected event.</p>
<div class="notes">
<p>Humans naturally seek explanations to update their understanding.</p>
</div>
<hr>
</section>
</section>
<section id="example-human-learning" class="level1">
<h1>Example: Human Learning</h1>
<p>A human feels unexpectedly sick and asks, “Why do I feel so sick?”</p>
<p>They learn that they get sick every time they eat those red berries.</p>
<p>They update their mental model and decide that the berries caused the sickness.</p>
<div class="notes">
<p>This is how humans naturally learn through explanation.</p>
</div>
<hr>
</section>
<section id="scientific-discovery" class="level1">
<h1>Scientific Discovery</h1>
<p>In many scientific disciplines, there is a change from qualitative to quantitative methods, and also towards data-driven modeling.</p>
<p>The goal of science is to gain knowledge, but many problems are solved with big datasets and complex statistical models.</p>
<div class="notes">
<p>Science is moving toward data-driven approaches.</p>
</div>
<hr>
</section>
<section id="the-model-as-knowledge-source" class="level1">
<h1>The Model as Knowledge Source</h1>
<p><strong>The model itself becomes the source of knowledge instead of the data.</strong></p>
<p>Interpretability makes it possible to extract this additional knowledge captured by the model.</p>
<div class="notes">
<p>Models can capture knowledge that goes beyond the original data.</p>
</div>
<hr>
</section>
<section id="safety-testing" class="level1">
<h1>Safety &amp; Testing</h1>
<p>Data models take on real-world tasks that require safety measures and testing.</p>
<p><strong>Example:</strong> A self-driving car automatically detects cyclists based on a computer vision system.</p>
<p>You want to be 100% sure that the abstraction the system has learned is error-free because running over cyclists is very bad.</p>
<div class="notes">
<p>Safety-critical applications require interpretability for validation.</p>
</div>
<hr>
</section>
<section id="bias-detection" class="level1">
<h1>Bias Detection</h1>
<p>By default, data models pick up biases from the training data.</p>
<p>This could make your models discriminate against underrepresented groups.</p>
<p><strong>Interpretability is a useful debugging tool for detecting bias in data models.</strong></p>
<div class="notes">
<p>Bias detection is crucial for fair AI systems.</p>
</div>
<hr>
</section>
<section id="social-acceptance" class="level1">
<h1>Social Acceptance</h1>
<p>The process of integrating machines and algorithms into our daily lives requires interpretability to increase social acceptance.</p>
<p><strong>Example:</strong> Our vacuum cleaner “DustBot” gets stuck. As an explanation for the accident, DustBot tells us that it needs to be on an even surface. This creates shared meaning and trust.</p>
<div class="notes">
<p>Explanations help build trust between humans and AI systems.</p>
</div>
<hr>
</section>
<section id="when-do-we-not-need-interpretability" class="level1">
<h1>When Do We NOT Need Interpretability?</h1>
<section id="low-impact-scenarios" class="level2">
<h2 class="anchored" data-anchor-id="low-impact-scenarios">Low-Impact Scenarios</h2>
<p>Interpretability is not required if the consequences of being wrong are minimal or acceptable.</p>
<p><strong>Example:</strong> Sarah’s personal Spotify playlist predictor that suggests songs she might like based on her listening history.</p>
<div class="notes">
<p>Low-stakes applications may not need interpretability.</p>
</div>
<hr>
</section>
</section>
<section id="well-studied-problems" class="level1">
<h1>Well-Studied Problems</h1>
<p>Some applications have been sufficiently well studied so that there is enough practical experience with the model.</p>
<p><strong>Example:</strong> Statistical models for optical character recognition that process images of envelopes and extract addresses.</p>
<p>These systems have been in use for many years, and it’s clear that they work.</p>
<div class="notes">
<p>Proven applications may not need additional interpretability.</p>
</div>
<hr>
</section>
<section id="gaming-prevention" class="level1">
<h1>Gaming Prevention</h1>
<p>Interpretability might enable people or programs to manipulate the system.</p>
<p><strong>Example:</strong> Facebook’s content ranking algorithm where users might manipulate their posts to game the system if they know which features affect visibility in their friends’ feeds.</p>
<div class="notes">
<p>Sometimes transparency can be exploited.</p>
</div>
<hr>
</section>
<section id="what-makes-a-good-explanation" class="level1">
<h1>What Makes a Good Explanation?</h1>
<section id="characteristics-of-human-friendly-explanations" class="level2">
<h2 class="anchored" data-anchor-id="characteristics-of-human-friendly-explanations">Characteristics of Human-Friendly Explanations</h2>
<div class="notes">
<p>These characteristics make explanations more effective for humans.</p>
</div>
<hr>
</section>
</section>
<section id="contrastive" class="level1">
<h1>Contrastive</h1>
<p>Humans usually don’t ask why a certain prediction was made, but why this prediction was made <strong>instead of another prediction</strong>.</p>
<p><strong>Example:</strong> For a house price prediction, the house owner might be interested in why does this beautiful house seem so cheap?</p>
<div class="notes">
<p>People want to understand why one outcome occurred instead of another.</p>
</div>
<hr>
</section>
<section id="selected" class="level1">
<h1>Selected</h1>
<p>People don’t expect explanations that cover the actual and complete list of causes of an event.</p>
<p>We are used to selecting one or two causes from a variety of possible causes as THE explanation.</p>
<p><strong>What it means for data modeling:</strong> Make the explanation short, give only 1 to 3 reasons, even if the world is more complex.</p>
<div class="notes">
<p>Humans prefer simple explanations over complex ones.</p>
</div>
<hr>
</section>
<section id="audience-focused" class="level1">
<h1>Audience-focused</h1>
<p>Explanations are part of a conversation or interaction between the explainer and the receiver of the explanation.</p>
<p><strong>Example:</strong> Explaining cryptocurrencies to a technical person vs.&nbsp;to your grandmother would be completely different.</p>
<div class="notes">
<p>Good explanations are tailored to the audience.</p>
</div>
<hr>
</section>
<section id="focus-on-abnormal" class="level1">
<h1>Focus on Abnormal</h1>
<p>People focus more on abnormal causes to explain events.</p>
<p>These are causes or effects that were not expected but nevertheless happened.</p>
<p><strong>Example:</strong> Viagra was originally developed as a heart medication, but researchers discovered its unexpected side effect during clinical trials.</p>
<div class="notes">
<p>Unexpected outcomes get more attention in explanations.</p>
</div>
<hr>
</section>
<section id="truthful" class="level1">
<h1>Truthful</h1>
<p>Good explanations prove to be true in reality (i.e., in other situations).</p>
<p><strong>Example:</strong> GPS satellites need to account for time dilation effects from Einstein’s theory of relativity.</p>
<p>The satellites’ clocks run faster in orbit due to weaker gravity, and this relativistic effect would cause GPS to be off by about 11 kilometers per day if not corrected.</p>
<div class="notes">
<p>Truthful explanations have predictive power.</p>
</div>
<hr>
</section>
<section id="consistent-with-prior-beliefs" class="level1">
<h1>Consistent with Prior Beliefs</h1>
<p>Humans often judge arguments by whether the conclusion fits their beliefs, rather than whether both their assumptions and their the reasoning are logically valid.</p>
<p>This is called the belief bias effect.</p>
<div class="notes">
<p>People tend to accept explanations that align with their existing beliefs.</p>
</div>
<hr>
</section>
<section id="classic-experiment-evans-barston-pollard-1983" class="level1">
<h1>Classic Experiment (Evans, Barston &amp; Pollard, 1983)</h1>
<p><strong>Premise 1:</strong> All mammals can walk.</p>
<p><strong>Premise 2:</strong> Whales are mammals.</p>
<p><strong>Conclusion:</strong> Whales can walk.</p>
<p>Although the conclusion is logically valid, it is completely unbelievable. Despite this, approximately 50% of participants would judge conclusions like this as true.</p>
<div class="notes">
<p>This demonstrates how beliefs can override logical reasoning.</p>
</div>
<hr>
</section>
<section id="the-dark-side" class="level1">
<h1>The Dark Side</h1>
<p>While belief consistency makes explanations more “human-friendly,” it’s arguably not very friendly to our future as a society.</p>
<p>We’re essentially designing systems that reinforce existing biases rather than challenging them.</p>
<div class="notes">
<p>This is a critical ethical consideration for AI systems.</p>
</div>
<hr>
</section>
<section id="example-loan-approval-model" class="level1">
<h1>Example: Loan Approval Model</h1>
<section id="the-problem" class="level2">
<h2 class="anchored" data-anchor-id="the-problem">The Problem</h2>
<p>A bank uses a statistical model to approve or reject loan applications.</p>
<p>The model performs well on test data, but applicants (and regulators) want to understand why decisions are made.</p>
<div class="notes">
<p>This is a real-world example where interpretability is crucial.</p>
</div>
<hr>
</section>
</section>
<section id="without-interpretability" class="level1">
<h1>Without Interpretability</h1>
<ul>
<li><strong>Applicant:</strong> “Why was my loan rejected?”</li>
<li><strong>Bank:</strong> “The model said no.”</li>
<li><strong>Result:</strong> Frustration, lack of trust, potential discrimination</li>
</ul>
<div class="notes">
<p>Black box decisions lead to problems.</p>
</div>
<hr>
</section>
<section id="with-interpretability" class="level1">
<h1>With Interpretability</h1>
<ul>
<li><strong>Applicant:</strong> “Why was my loan rejected?”</li>
<li><strong>Bank:</strong> “Your application was rejected because your debt-to-income ratio is 45% (our threshold is 40%) and you have two recent late payments. If you can reduce your debt-to-income ratio to below 40% and maintain on-time payments for 6 months, you would likely be approved.”</li>
<li><strong>Result:</strong> Clear guidance, trust, actionable steps</li>
</ul>
<div class="notes">
<p>Interpretable decisions provide clear guidance and build trust.</p>
</div>
<hr>
</section>
<section id="legal-requirements" class="level1">
<h1>Legal Requirements</h1>
<section id="banks-must-provide-interpretability" class="level2">
<h2 class="anchored" data-anchor-id="banks-must-provide-interpretability">Banks Must Provide Interpretability</h2>
<p><strong>Equal Credit Opportunity Act (ECOA)</strong> - Requires lenders to provide “adverse action notices” that explain why credit was denied, including the specific reasons for the decision.</p>
<div class="notes">
<p>This is a legal requirement, not just a best practice.</p>
</div>
<hr>
</section>
</section>
<section id="interpretable-models" class="level1">
<h1>Interpretable Models</h1>
<ul>
<li><strong>Linear regression</strong>: Clear coefficients and additive structure</li>
<li><strong>Decision trees</strong>: Simple if-then rules</li>
<li><strong>Simple Bayesian models</strong>: Transparent conditional probabilities</li>
<li><strong>Rule-based systems</strong>: Explicit logical statements</li>
</ul>
<div class="notes">
<p>These model types are inherently interpretable.</p>
</div>
<hr>
</section>
<section id="less-interpretable-models" class="level1">
<h1>Less Interpretable Models</h1>
<ul>
<li><strong>Deep neural networks</strong>: Complex non-linear transformations</li>
<li><strong>Ensemble models</strong>: Random forests, gradient boosting (without explanation tools)</li>
<li><strong>Support vector machines</strong>: High-dimensional transformations</li>
<li><strong>Complex statistical models</strong>: Many interactions and non-linearities</li>
</ul>
<div class="notes">
<p>These models are harder to interpret but may be more accurate.</p>
</div>
<hr>
</section>
<section id="in-short" class="level1">
<h1>In Short</h1>
<p><strong>Interpretability means models aren’t just accurate — they’re understandable.</strong></p>
<div class="notes">
<p>This is the key takeaway from the interpretability discussion.</p>
</div>
<hr>
</section>
<section id="linear-regression-example" class="level1">
<h1>Linear Regression Example</h1>
<section id="buildit-inc.-house-flipping" class="level2">
<h2 class="anchored" data-anchor-id="buildit-inc.-house-flipping">BuildIt Inc.&nbsp;House Flipping</h2>
<p>BuildIt Inc.&nbsp;flips houses - they buy houses to quickly renovate and then sell.</p>
<p>Their specialty is building additions on to existing houses in established neighborhoods and then selling the home at prices above their total investment.</p>
<div class="notes">
<p>This is a practical business example of using interpretable models.</p>
</div>
<hr>
</section>
</section>
<section id="buildits-decision-criteria" class="level1">
<h1>BuildIt’s Decision Criteria</h1>
<p>BuildIt’s decision to move into a neighborhood is based on how sales price fluctuates with square footage.</p>
<p>If sales price seems to increase by more than $120 per additional square foot, then they consider that neighborhood to be a good candidate for buying houses.</p>
<div class="notes">
<p>They have a clear business rule based on interpretable metrics.</p>
</div>
<hr>
</section>
<section id="buildits-data" class="level1">
<h1>BuildIt’s Data</h1>
<p>Here is the <code>python</code> code that creates a dataframe with BuildIt’s data (note: <code>salesPrice</code> is in thousands of dollars):</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">## make two data arrays representing observations</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">## of six home sales</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>salesPrice <span class="op">=</span> [<span class="dv">160</span>, <span class="dv">220</span>, <span class="dv">190</span>, <span class="dv">250</span>, <span class="dv">290</span>, <span class="dv">240</span>]</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>sqFootage <span class="op">=</span> [<span class="dv">960</span>, <span class="dv">1285</span>, <span class="dv">1350</span>, <span class="dv">1600</span>, <span class="dv">1850</span>, <span class="dv">1900</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="notes">
<p>This is the actual data they collected.</p>
</div>
<hr>
</section>
<section id="visualizing-the-relationship" class="level1">
<h1>Visualizing the Relationship</h1>
<p>Visually, we can confirm what appears to be a linear relationship between square footage and sales prices by creating a scatterplot with a linear regression line drawn in blue:</p>
<div class="notes">
<p>The visualization helps confirm the linear relationship.</p>
</div>
<hr>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: A plausible regression line placed through the six observed sales.</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-firstPlot</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn.objects <span class="im">as</span> so</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seaborn style</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    so.Plot(x<span class="op">=</span>sqFootage, y<span class="op">=</span>salesPrice)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    .add(so.Dots(pointsize <span class="op">=</span> <span class="dv">12</span>)) <span class="co">## big points</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    .add(so.Line(), so.PolyFit(order <span class="op">=</span> <span class="dv">1</span>)) <span class="co">## adds regression line</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    .label(x<span class="op">=</span><span class="st">"Square Footage"</span>, y<span class="op">=</span><span class="st">"Sales Price in (000's)"</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    .show()</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="buildits-key-question" class="level1">
<h1>BuildIt’s Key Question</h1>
<p>BuildIt is interested in the slope of this line which gives the estimated change in mean sales price for each unit change in square footage.</p>
<p>For BuildIt, they want to know if this slope is above $120 per square foot because at that price point the firm is confident it can make money?</p>
<div class="notes">
<p>The slope is the key business metric they need to understand.</p>
</div>
<hr>
</section>
<section id="mathematical-notation" class="level1">
<h1>Mathematical Notation</h1>
<p>Letting,</p>
<p><span class="math display">\[
\begin{aligned}
x_i \equiv &amp;\textrm{ The square footage for the } i^{th} \textrm{ house.} \\
y_i \equiv &amp;\textrm{ The observed sales price, in 000's, for the } i^{th} \textrm{ house.} \\
\alpha \equiv &amp;\textrm{ The intercept term for the regression line.} \\
\beta \equiv &amp;\textrm{ The slope coefficient representing change in expected price per square footage.} \\
\mu_i \equiv &amp;\textrm{ The expected sales price, in 000's, for any given square footage where } \\
&amp; \hspace{0.2cm} \mu_i = E(y_i | x_i) \textrm{ and } \mu_i = \alpha + \beta \times x_i.
\end{aligned}
\]</span></p>
<div class="notes">
<p>This notation helps us understand the mathematical structure.</p>
</div>
<hr>
</section>
<section id="linear-regression-output" class="level1">
<h1>Linear Regression Output</h1>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>np.polyfit(x <span class="op">=</span> sqFootage, y <span class="op">=</span> salesPrice, deg <span class="op">=</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In the below code output, the first element of the returned array is <span class="math inline">\(\beta\)</span>, the slope coefficient for how price changes per square foot and the second element of the array is <span class="math inline">\(\alpha\)</span> typically referred to as the y-intercept.</p>
<div class="notes">
<p>This code calculates the regression coefficients.</p>
</div>
<hr>
</section>
<section id="the-best-fit-line" class="level1">
<h1>The Best Fit Line</h1>
<p>Based on the output, the following linear equation is the so-called “best” line:</p>
<p><span class="math display">\[
\mu_i = 58.91 + 0.1114 \times x_i
\]</span></p>
<div class="notes">
<p>This is the mathematical model that describes the relationship.</p>
</div>
<hr>
</section>
<section id="business-interpretation" class="level1">
<h1>Business Interpretation</h1>
<p>The model suggests, assuming its assumptions are justified, that BuildIt can anticipate being able to sell additional square footage for about $111 per square foot (i.e.&nbsp;<span class="math inline">\(1000* \beta\)</span> because price is in 000’s).</p>
<p>This would not earn them acceptable profit as it is less than $120 per square foot.</p>
<div class="notes">
<p>The business interpretation shows this neighborhood doesn’t meet their criteria.</p>
</div>
<hr>
</section>
<section id="uncertainty-consideration" class="level1">
<h1>Uncertainty Consideration</h1>
<p>However, with only <code>6</code> data points, there is obviously going to be tremendous uncertainty in this estimate.</p>
<div class="notes">
<p>Small sample sizes lead to high uncertainty in estimates.</p>
</div>
<hr>
</section>
<section id="visualizing-as-a-generative-dag" class="level1">
<h1>Visualizing as a Generative DAG</h1>
<p>From previous coursework, you are probably familiar with simple linear regression equation expressed mathematically.</p>
<p>This model can be visually expressed as a generative model with the assumption that our observed data is normally distributed around some line of expected sales prices.</p>
<div class="notes">
<p>The DAG helps visualize the probabilistic structure of the model.</p>
</div>
<hr>
</section>
<section id="mathematical-structure" class="level1">
<h1>Mathematical Structure</h1>
<p><span class="math display">\[
\mu_i = \alpha + \beta x_i
\]</span></p>
<p>where,</p>
<p><span class="math display">\[
\begin{aligned}
x_i &amp;\equiv \textrm{The value of an explanatory variable for the } i^{th} \textrm{ observation.} \\
\alpha &amp;\equiv \textrm{ The intercept term for the line.} \\
\beta &amp;\equiv \textrm{ The slope coefficient for the line.} \\
\mu_i &amp;\equiv \textrm{ The expected value (or mean) for the } i^{th} \textrm{ observation.}
\end{aligned}
\]</span></p>
<div class="notes">
<p>This defines the mathematical components of the model.</p>
</div>
<hr>
</section>
<section id="generative-dag-visualization" class="level1">
<h1>Generative DAG Visualization</h1>
<p>Using a generative DAG, <strong>?@fig-lineDag</strong> presents a graphical version of simple linear regression.</p>
<div class="notes">
<p>The DAG shows the probabilistic relationships between variables.</p>
</div>
<hr>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-lineDag</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Generative DAG model for linear regression.</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">#| out-width: 85%</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> partial, partialmethod</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> daft   <span class="co">### %pip install -U git+https://github.com/daft-dev/daft.git</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> default_rng</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> dag(daft.PGM):</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        daft.PGM.<span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    obsNode <span class="op">=</span> partialmethod(daft.PGM.add_node, scale <span class="op">=</span> <span class="fl">1.0</span>, aspect <span class="op">=</span> <span class="dv">3</span>, fontsize <span class="op">=</span> <span class="dv">9</span>, plot_params <span class="op">=</span> {<span class="st">'facecolor'</span>: <span class="st">'cadetblue'</span>})</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    decNode <span class="op">=</span> partialmethod(daft.PGM.add_node, aspect <span class="op">=</span> <span class="fl">2.2</span>, fontsize <span class="op">=</span> <span class="dv">9</span>, shape <span class="op">=</span> <span class="st">"rectangle"</span>, plot_params <span class="op">=</span> {<span class="st">'facecolor'</span>: <span class="st">'thistle'</span>})</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    detNode <span class="op">=</span> partialmethod(daft.PGM.add_node, scale <span class="op">=</span> <span class="fl">1.0</span>, aspect <span class="op">=</span> <span class="dv">3</span>, fontsize <span class="op">=</span> <span class="fl">8.5</span>, alternate <span class="op">=</span> <span class="va">True</span>, plot_params <span class="op">=</span> {<span class="st">'facecolor'</span>: <span class="st">'aliceblue'</span>})</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    latNode <span class="op">=</span> partialmethod(daft.PGM.add_node, scale <span class="op">=</span> <span class="fl">1.0</span>, aspect <span class="op">=</span> <span class="fl">3.45</span>, fontsize <span class="op">=</span> <span class="fl">8.5</span>, plot_params <span class="op">=</span> {<span class="st">'facecolor'</span>: <span class="st">'aliceblue'</span>})</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    detNodeBig <span class="op">=</span> partialmethod(daft.PGM.add_node, scale <span class="op">=</span> <span class="fl">1.2</span>, aspect <span class="op">=</span> <span class="fl">2.25</span>, fontsize <span class="op">=</span> <span class="dv">9</span>, alternate <span class="op">=</span> <span class="va">True</span>, plot_params <span class="op">=</span> {<span class="st">'facecolor'</span>: <span class="st">'aliceblue'</span>})</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    latNodeBig <span class="op">=</span> partialmethod(daft.PGM.add_node, scale <span class="op">=</span> <span class="fl">1.2</span>, aspect <span class="op">=</span> <span class="fl">2.2</span>, fontsize <span class="op">=</span> <span class="dv">9</span>, plot_params <span class="op">=</span> {<span class="st">'facecolor'</span>: <span class="st">'aliceblue'</span>})</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>pgm <span class="op">=</span> dag(dpi <span class="op">=</span> <span class="dv">100</span>, alternate_style<span class="op">=</span><span class="st">"outer"</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>pgm.latNode(<span class="st">"y"</span>,<span class="st">"Sales Price</span><span class="ch">\n</span><span class="st">"</span><span class="op">+</span><span class="vs">r"</span><span class="dv">$</span><span class="vs">y </span><span class="dv">\s</span><span class="vs">im Normal</span><span class="kw">(</span><span class="dv">\m</span><span class="vs">u,</span><span class="dv">\s</span><span class="vs">igma</span><span class="kw">)</span><span class="dv">$</span><span class="vs">"</span>,<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>pgm.detNode(<span class="st">"mu"</span>,<span class="st">"Exp. Sales Price</span><span class="ch">\n</span><span class="st">"</span><span class="op">+</span><span class="vs">r"</span><span class="dv">$\m</span><span class="vs">u = </span><span class="ch">\a</span><span class="vs">lpha </span><span class="op">+</span><span class="vs"> </span><span class="dv">\b</span><span class="vs">eta </span><span class="ch">\t</span><span class="vs">imes x</span><span class="dv">$</span><span class="vs">"</span>,<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>pgm.obsNode(<span class="st">"x"</span>,<span class="st">"Square Footage</span><span class="ch">\n</span><span class="st">"</span><span class="op">+</span><span class="vs">r"</span><span class="dv">$</span><span class="vs">x</span><span class="dv">$</span><span class="vs">"</span>,<span class="dv">1</span>,<span class="dv">3</span>, aspect <span class="op">=</span> <span class="fl">2.7</span>)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>pgm.latNode(<span class="st">"alpha"</span>,<span class="st">"Intercept Term</span><span class="ch">\n</span><span class="st">"</span><span class="op">+</span><span class="vs">r"</span><span class="dv">$</span><span class="ch">\a</span><span class="vs">lpha = 58</span><span class="dv">.</span><span class="vs">91</span><span class="dv">$</span><span class="vs">"</span>, <span class="op">-</span><span class="fl">1.5</span>, <span class="dv">3</span>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>pgm.latNode(<span class="st">"beta"</span>,<span class="st">"Slope Coeff "</span> <span class="op">+</span> <span class="vs">r"</span><span class="dv">$</span><span class="kw">(</span><span class="ch">\$</span><span class="vs"> / ft</span><span class="dv">^</span><span class="op">{2}</span><span class="kw">)</span><span class="dv">$</span><span class="vs">"</span> <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span><span class="op">+</span><span class="vs">r"</span><span class="dv">$\b</span><span class="vs">eta = 0</span><span class="dv">.</span><span class="vs">1114</span><span class="dv">$</span><span class="vs">"</span>, <span class="fl">3.5</span>, <span class="dv">3</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>pgm.latNode(<span class="st">"sigma"</span>,<span class="st">"Sales $ Std.Dev"</span> <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span><span class="op">+</span><span class="vs">r"</span><span class="dv">$\s</span><span class="vs">igma = 24</span><span class="dv">.</span><span class="vs">8</span><span class="dv">$</span><span class="vs">"</span>, <span class="fl">3.5</span>, <span class="dv">2</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>pgm.add_edge(<span class="st">"mu"</span>,<span class="st">"y"</span>)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>pgm.add_edge(<span class="st">"x"</span>,<span class="st">"mu"</span>)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>pgm.add_edge(<span class="st">"alpha"</span>,<span class="st">"mu"</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>pgm.add_edge(<span class="st">"beta"</span>,<span class="st">"mu"</span>)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>pgm.add_edge(<span class="st">"sigma"</span>,<span class="st">"y"</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>pgm.add_plate([<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">2.4</span>, <span class="fl">3.25</span>], label <span class="op">=</span> <span class="st">"Observation:</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="vs">r"</span><span class="dv">$</span><span class="vs">i = 1, 2, </span><span class="er">\</span><span class="vs">ldots, 6</span><span class="dv">$</span><span class="vs">"</span>, </span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>              label_offset <span class="op">=</span> (<span class="dv">2</span>,<span class="dv">2</span>), rect_params <span class="op">=</span> <span class="bu">dict</span>({<span class="st">"fill"</span>: <span class="va">False</span>, <span class="st">"linestyle"</span>: <span class="st">"dashed"</span>, <span class="st">"edgecolor"</span>: <span class="st">"black"</span>}))</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>pgm.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="dag-narrative" class="level1">
<h1>DAG Narrative</h1>
<p>The statistical model of the generative DAG in <strong>?@fig-lineDag</strong>, let’s digest the implied narrative. Starting at the bottom:</p>
<ul>
<li><em>Sales Price</em> Node(<span class="math inline">\(y\)</span>): We observe <em>Sales Price</em> data where each realization is normally distributed about an <em>Expected Sales Price</em>, <span class="math inline">\(\mu\)</span>.</li>
</ul>
<div class="notes">
<p>The DAG shows the probabilistic structure of the model.</p>
</div>
<hr>
</section>
<section id="dag-narrative-continued" class="level1">
<h1>DAG Narrative (continued)</h1>
<ul>
<li><em>Expected Sales Price</em> Node(<span class="math inline">\(\mu\)</span>): Each realization <span class="math inline">\(\mu\)</span> is actually a deterministic function of this node’s parents. Graphically, the double perimeter around the node signals this. This expectation varies with each observation. The only way this can happen is that it has a parent that varies with each observation; namely <em>Square Footage</em>.</li>
</ul>
<div class="notes">
<p>The expected price is determined by the square footage.</p>
</div>
<hr>
</section>
<section id="dag-narrative-continued-1" class="level1">
<h1>DAG Narrative (continued)</h1>
<ul>
<li><em>Square Footage</em> Node(<span class="math inline">\(x\)</span>): The <em>Square Footage</em> is our model input (as noted by the darker fill); we just take the observed data as given.</li>
</ul>
<div class="notes">
<p>Square footage is the input variable we observe.</p>
</div>
<hr>
</section>
<section id="dag-narrative-continued-2" class="level1">
<h1>DAG Narrative (continued)</h1>
<ul>
<li>All other yet-to-be discussed nodes are outside the <em>Observations</em> plate. Therefore, each prediction from the model will use a constant value for each of these nodes. The node we are most interested in is <em>Slope Coeff</em>, <span class="math inline">\(\beta\)</span>, as this is as an estimate of how home prices change when Build-It adds square footage. <em>Intercept</em> just sets some base-level home value and <em>Price Std. Dev.</em> gives a measure of how much home prices vary about the calculated expected price, <span class="math inline">\(\mu\)</span>.</li>
</ul>
<div class="notes">
<p>The slope coefficient is the key business metric.</p>
</div>
<hr>
</section>
<section id="further-reading" class="level1">
<h1>Further Reading</h1>
<p>For a nice companion guide to interpretable machine learning methods and techniques, see:</p>
<p><strong>Molnar, C. (2023). Interpretable Machine Learning: A Guide for Making Black Box Models Explainable.</strong> Available at: https://christophm.github.io/interpretable-ml-book/</p>
<div class="notes">
<p>This is an excellent resource for learning more about interpretable ML.</p>
</div>
<hr>
</section>
<section id="key-takeaway" class="level1">
<h1>Key Takeaway</h1>
<p><em>“The most compelling analysts unify narrative, math, and code.”</em></p>
<div class="notes">
<p>This quote captures the essence of good data analysis.</p>
</div>
<hr>
</section>
<section id="questions" class="level1">
<h1>Questions?</h1>
<section id="thank-you-for-your-attention" class="level2">
<h2 class="anchored" data-anchor-id="thank-you-for-your-attention">Thank you for your attention!</h2>
<div class="notes">
<p>This concludes the presentation on interpretable data models.</p>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>